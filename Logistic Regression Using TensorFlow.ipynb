{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Digits DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Note that this data set is not actually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here data is an object which has data, target, target_names, etc. as attributes.\n",
    "# We are only interested in data.data \n",
    "\n",
    "X = data.data;\n",
    "Y = data.target;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1797, 64), (1797,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into Test-Train set 70% ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.3, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1257, 64), (540, 64), (1257,), (540,))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape, xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform one hot encoding of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc= OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain = enc.fit_transform(ytrain.reshape(-1,1)).toarray()\n",
    "ytest =  enc.fit_transform(ytest.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_in = tf.placeholder(tf.float32, [None,xtrain.shape[1]])\n",
    "Y_in = tf.placeholder(tf.float32, [None,ytrain.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.python.ops.variables.RefVariable,\n",
       " tensorflow.python.ops.variables.RefVariable,\n",
       " TensorShape([Dimension(10)]),\n",
       " TensorShape([Dimension(64), Dimension(10)]))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W =  tf.Variable(tf.zeros([xtrain.shape[1],ytrain.shape[1]]))  ## W here is 64*10 matrix\n",
    "b =  tf.Variable(tf.zeros([ytrain.shape[1]]))# b is 10*1 vector\n",
    "type(W),type(b),b.shape,W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predicting the outcome \n",
    "Y_out =  tf.nn.softmax(tf.matmul(X_in,W) + b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross Entropy Loss Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(Y_in*tf.log(Y_out), reduction_indices=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predictions_OP = tf.equal(tf.argmax(Y_out,1),tf.argmax(Y_in,1))\n",
    "\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Optimizer\n",
    "optimizer =  tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "init  = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.8225934505462646\n",
      "Train Accuracy 0.9443118572235107\n",
      "Train Accuracy 0.9554494619369507\n",
      "Train Accuracy 0.9618138670921326\n",
      "Train Accuracy 0.9649960398674011\n",
      "Train Accuracy 0.9689737558364868\n",
      "Train Accuracy 0.9737470149993896\n",
      "Train Accuracy 0.9753381013870239\n",
      "Train Accuracy 0.9769291877746582\n",
      "Train Accuracy 0.9801113605499268\n",
      "Train Accuracy 0.9801113605499268\n",
      "Train Accuracy 0.9801113605499268\n",
      "Train Accuracy 0.981702446937561\n",
      "Train Accuracy 0.9824979901313782\n",
      "Train Accuracy 0.9824979901313782\n",
      "Train Accuracy 0.9824979901313782\n",
      "Train Accuracy 0.9848846197128296\n",
      "Train Accuracy 0.9848846197128296\n",
      "Train Accuracy 0.9856801629066467\n",
      "Train Accuracy 0.9864757061004639\n",
      "Train Accuracy 0.9872713088989258\n",
      "Train Accuracy 0.9888623952865601\n",
      "Train Accuracy 0.9888623952865601\n",
      "Train Accuracy 0.9888623952865601\n",
      "Train Accuracy 0.9896579384803772\n",
      "Train Accuracy 0.9896579384803772\n",
      "Train Accuracy 0.9904534816741943\n",
      "Train Accuracy 0.9904534816741943\n",
      "Train Accuracy 0.9912490248680115\n",
      "Train Accuracy 0.9912490248680115\n",
      "Train Accuracy 0.9920445680618286\n",
      "Train Accuracy 0.9920445680618286\n",
      "Train Accuracy 0.9920445680618286\n",
      "Train Accuracy 0.9920445680618286\n",
      "Train Accuracy 0.9920445680618286\n",
      "Train Accuracy 0.9928401112556458\n",
      "Train Accuracy 0.9936356544494629\n",
      "Train Accuracy 0.9936356544494629\n",
      "Train Accuracy 0.9936356544494629\n",
      "Train Accuracy 0.99443119764328\n",
      "Train Accuracy 0.9952267408370972\n",
      "Train Accuracy 0.9952267408370972\n",
      "Train Accuracy 0.9952267408370972\n",
      "Train Accuracy 0.9960222840309143\n",
      "Train Accuracy 0.9960222840309143\n",
      "Train Accuracy 0.9960222840309143\n",
      "Train Accuracy 0.9960222840309143\n",
      "Train Accuracy 0.9960222840309143\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9968178272247314\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n",
      "Train Accuracy 0.9976133704185486\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "train_accuracy = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for ep in range(epochs):\n",
    "        sess.run(optimizer, feed_dict = {X_in: xtrain, Y_in:ytrain})\n",
    "        l = sess.run(loss, feed_dict = {X_in: xtrain, Y_in:ytrain})\n",
    "        acc = sess.run(accuracy_OP, feed_dict = {X_in: xtrain, Y_in:ytrain})\n",
    "        loss_values.append(l)\n",
    "        train_accuracy.append(acc)\n",
    "        if ep % 20 == 0:\n",
    "            print(f\"Train Accuracy {acc}\")\n",
    "    Weight =  sess.run(W, feed_dict = {X_in: xtrain, Y_in:ytrain})\n",
    "    bias  =   sess.run(b,feed_dict = {X_in: xtrain, Y_in:ytrain})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 10)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "518/540 = 0.9592592592592593\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(xtest.shape[0]):\n",
    "    z = np.matmul(xtest[i],Weight) + bias\n",
    "    zp = np.exp(z) /np.sum(np.exp(z))\n",
    "    if np.argmax(zp) == np.argmax(ytest[i]):\n",
    "        count += 1\n",
    "print(f\"{count}/{xtest.shape[0]} = {count/xtest.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
