{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\himan\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Architecture of our network is:\n",
    "    \n",
    "- (Input) -> [batch_size, 28, 28, 1]  >> Apply 32 filter of [5x5]\n",
    "- (Convolutional layer 1)  -> [batch_size, 28, 28, 32]\n",
    "- (ReLU 1)  -> [?, 28, 28, 32]\n",
    "- (Max pooling 1) -> [?, 14, 14, 32]\n",
    "- (Convolutional layer 2)  -> [?, 14, 14, 64] \n",
    "- (ReLU 2)  -> [?, 14, 14, 64] \n",
    "- (Max pooling 2)  -> [?, 7, 7, 64] \n",
    "- [fully connected layer 3] -> [1x1024]\n",
    "- [ReLU 3]  -> [1x1024]\n",
    "- [Drop out]  -> [1x1024]\n",
    "- [fully connected layer 4] -> [1x10]\n",
    "\n",
    "\n",
    "The next cells will explore this new architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Paramters for Model\n",
    "width = 28 # width of the image in pixels \n",
    "height = 28 # height of the image in pixels\n",
    "flat = width * height # number of pixels in one image \n",
    "class_output = 10 # number of possible classifications for the problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Placeholders for data\n",
    "x_in = tf.placeholder(tf.float32,shape= [None, flat])\n",
    "y_in = tf.placeholder(tf.float32,shape= [None,class_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 28, 28, 1) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## The input image is 28 pixels by 28 pixels, 1 channel (grayscale). We will reshape it\n",
    "##In this case, the first dimension is the batch number of the image, \n",
    "##and can be of any size (so we set it to -1). \n",
    "##The second and third dimensions are width and height,\n",
    "##and the last one is the image channels.\n",
    "x_image = tf.reshape(x_in,[-1,width,height,1])\n",
    "x_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_conv1_size = (5,5) ## Size of filter of first covolutional Layer\n",
    "n_filter_conv1 = 32 ## Number of filters of first convolutional layer\n",
    "stride1 = [1,1,1,1] ## [batch_size,widht,height,channels]\n",
    "maxpoolfilter1 = [1,2,2,1] ## [batch_size,widht,height,channels]\n",
    "maxpoolstride1 = [1,2,2,1] ## Stride to perform for maxpool. Here 2*2 is taken so that kernels don't overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_conv1 = tf.Variable(tf.truncated_normal([filter_conv1_size[0],filter_conv1_size[1],1,n_filter_conv1], stddev =0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1, shape=[32])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform Convolution\n",
    "convolve1 = tf.nn.conv2d(x_image, w_conv1, strides=stride1, padding='SAME') + b_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply RELU Function\n",
    "h_conv1 = tf.nn.relu(convolve1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_2:0' shape=(?, 14, 14, 32) dtype=float32>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply maxpooling to Layer1\n",
    "conv1_out =  tf.nn.max_pool(h_conv1, ksize = maxpoolfilter1, strides = maxpoolstride1, padding = 'SAME')\n",
    "conv1_out\n",
    "## size of conv1_out = [batch_size,14,14,32]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Convolution Layer\n",
    "\n",
    "We apply convolution again at this layer.\n",
    "Filter_size = (5,5)\n",
    "Number of InputChannels = 32 (from previous layer as result of applying 32 filters)\n",
    "In this layer we will apply 64 filters.\n",
    "\n",
    "<b>Notice:</b> here, the input image is [14x14x32], the filter is [5x5x32], we use 64 filters of size [5x5x32], and the output of the convolutional layer would be 64 convolved image, [14x14x64].\n",
    "\n",
    "<b>Notice:</b> the convolution result of applying a filter of size [5x5x32] on image of size [14x14x32] is an image of size [14x14x1], that is, the convolution is functioning on volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels_2 = 32  ## From previous input layer\n",
    "filter_conv2_size = (5,5) ## Size of filter of first covolutional Layer\n",
    "n_filter_conv2 = 64 ## Number of filters of first convolutional layer\n",
    "stride2 = [1,1,1,1] ## [batch_size,widht,height,channels]\n",
    "maxpoolfilter2 = [1,2,2,1] ## [batch_size,widht,height,channels]\n",
    "maxpoolstride2 = [1,2,2,1] ## Stride to perform for maxpool. Here 2*2 is taken so that kernels don't overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_8:0' shape=(5, 5, 32, 64) dtype=float32_ref> <tf.Variable 'Variable_9:0' shape=(64,) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "w_conv2 = tf.Variable(tf.truncated_normal([filter_conv2_size[0],filter_conv2_size[1],n_channels_2,n_filter_conv2], stddev =0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1, shape=[n_filter_conv2])) \n",
    "print(w_conv2,b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_4:0' shape=(?, 14, 14, 64) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolve2 = tf.nn.conv2d(conv1_out, w_conv2, strides=stride2, padding='SAME') + b_conv2\n",
    "convolve2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_conv2 = tf.nn.relu(convolve2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'MaxPool_3:0' shape=(?, 7, 7, 64) dtype=float32>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2_out = tf.nn.max_pool(h_conv2, ksize = maxpoolfilter2, strides= maxpoolstride2,padding = 'SAME')\n",
    "conv2_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully connected Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flatten the conv2_out \n",
    "flatten_matrix = tf.reshape(conv2_out, [-1, 7 * 7 * 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First Layer consists 1024 hidden units\n",
    "w_fc1 = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024])) # need 1024 biases for 1024 outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1 = tf.matmul(flatten_matrix, w_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dropout/mul:0' shape=(?, 1024) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Drop out Layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "layer_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "layer_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ouput Layer\n",
    "w_fc2 = tf.Variable(tf.truncated_normal([1024, 10], stddev=0.1)) #1024 neurons\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10])) # 10 possibilities for digits [0,1,2,3,4,5,6,7,8,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc2 =  tf.matmul(layer_drop, w_fc2) + b_fc2\n",
    "y_out =  tf.nn.softmax(fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss Function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_in * tf.log(y_out), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_out, 1), tf.argmax(y_in, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.06\n",
      "step 100, training accuracy 0.8\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.9\n",
      "step 500, training accuracy 0.96\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.98\n",
      "step 800, training accuracy 0.98\n",
      "step 900, training accuracy 0.92\n",
      "step 1000, training accuracy 0.92\n",
      "step 1100, training accuracy 0.92\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 0.94\n",
      "step 1400, training accuracy 0.96\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 0.96\n",
      "step 1900, training accuracy 0.96\n",
      "step 2000, training accuracy 0.92\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 0.98\n",
      "step 2300, training accuracy 0.98\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 0.94\n",
      "step 2600, training accuracy 0.98\n",
      "step 2700, training accuracy 0.98\n",
      "step 2800, training accuracy 1\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 0.98\n",
      "step 3100, training accuracy 0.98\n",
      "step 3200, training accuracy 0.96\n",
      "step 3300, training accuracy 0.92\n",
      "step 3400, training accuracy 1\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 1\n",
      "step 3700, training accuracy 1\n",
      "step 3800, training accuracy 0.98\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 1\n",
      "step 4100, training accuracy 0.96\n",
      "step 4200, training accuracy 0.96\n",
      "step 4300, training accuracy 0.98\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 1\n",
      "step 4600, training accuracy 1\n",
      "step 4700, training accuracy 1\n",
      "step 4800, training accuracy 0.94\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 0.98\n",
      "step 5200, training accuracy 0.98\n",
      "step 5300, training accuracy 1\n",
      "step 5400, training accuracy 0.98\n",
      "step 5500, training accuracy 0.98\n",
      "step 5600, training accuracy 0.98\n",
      "step 5700, training accuracy 0.98\n",
      "step 5800, training accuracy 1\n",
      "step 5900, training accuracy 1\n",
      "step 6000, training accuracy 0.98\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 1\n",
      "step 6400, training accuracy 0.98\n",
      "step 6500, training accuracy 1\n",
      "step 6600, training accuracy 1\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 1\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 1\n",
      "step 7300, training accuracy 0.98\n",
      "step 7400, training accuracy 0.96\n",
      "step 7500, training accuracy 0.94\n",
      "step 7600, training accuracy 1\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 0.98\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 0.98\n",
      "step 8500, training accuracy 0.98\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 1\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 0.94\n",
      "test accuracy 0.9904000040888786\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ### Train the batch\n",
    "    for i in range(10000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i%100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_in:batch[0], y_in: batch[1], keep_prob: 1.0})\n",
    "            print(\"step %d, training accuracy %g\"%(i, float(train_accuracy)))\n",
    "        optimizer.run(feed_dict={x_in: batch[0], y_in: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "    ## Finding Testing Accuracy\n",
    "    # evaluate in batches to avoid out-of-memory issues\n",
    "    n_batches = mnist.test.images.shape[0] // 50\n",
    "    cumulative_accuracy = 0.0\n",
    "    for index in range(n_batches):\n",
    "        batch = mnist.test.next_batch(50)\n",
    "        cumulative_accuracy += accuracy.eval(feed_dict={x_in: batch[0], y_in: batch[1], keep_prob: 1.0})\n",
    "    print(\"test accuracy {}\".format(cumulative_accuracy / n_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
